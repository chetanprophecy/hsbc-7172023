{"initCode":"","code":"udf(\n    (\n      _p_filedate:                String,\n      _p_config_file:             String,\n      _p_default_fileset_version: String,\n      _p_feed_identifier:         String\n    ) => {\n      var p_filedate                               = _p_filedate\n      var p_config_file                            = _p_config_file\n      var p_default_fileset_version                = _p_default_fileset_version\n      var p_feed_identifier                        = _p_feed_identifier\n      var fileset_version_count                    = 0\n      var fileset_version_rules_current            = Row(\"\",                                                         \"\", \"\")\n      var fileset_version_rules_current_vec        = Array[Row]()\n      var fileset_version_rules_current_vec_sorted = Array[Row]()\n      val data                                     = loadLookupData(readLookupFile(p_config_file.toString).toString, \"|\")\n      var current_fileset_version                  = \"\"\n      _createLookup(\n        \"fileset_version_lookup\",\n        loadLookupData(readLookupFile(p_config_file.toString).toString, \"|\"),\n        List(\"feed_identifier\"),\n        \"feed_identifier\",\n        \"version_date\",\n        \"version\"\n      )\n      fileset_version_count =\n        if (\n          (try _lookup_count(\"fileset_version_lookup\", p_feed_identifier.toString)\n          catch {\n            case error: Throwable => null\n          }) != null\n        )\n          _lookup_count(\"fileset_version_lookup\", p_feed_identifier.toString)\n        else\n          0\n      (0 until convertToInt(fileset_version_count)).zipWithIndex\n        .map({\n          case (_i, iIndex) =>\n            var i = _i\n            fileset_version_rules_current = new org.apache.spark.sql.catalyst.expressions.GenericRowWithSchema(\n              Array(\n                _lookup_row(\"fileset_version_lookup\", p_feed_identifier)(\n                  convertToInt(i)\n                ).array(convertToInt(0)).toString,\n                _lookup_row(\"fileset_version_lookup\", p_feed_identifier)(\n                  convertToInt(i)\n                ).array(convertToInt(1)),\n                _lookup_row(\"fileset_version_lookup\", p_feed_identifier)(\n                  convertToInt(i)\n                ).array(convertToInt(2)).toString\n              ),\n              StructType(\n                List(StructField(\"feed_identifier\", StringType, true),\n                     StructField(\"version_date\",    StringType, true),\n                     StructField(\"version\",         StringType, true)\n                )\n              )\n            )\n            fileset_version_rules_current_vec =\n              Array.concat(fileset_version_rules_current_vec, Array.fill(1)(fileset_version_rules_current))\n        })\n        .toArray\n      fileset_version_rules_current_vec_sorted =\n        fileset_version_rules_current_vec.sortBy(x => x.getAs[String](\"version_date\"))\n      import scala.util.control._\n      val outer_loop = new Breaks\n      outer_loop.breakable {\n        fileset_version_rules_current_vec_sorted.zipWithIndex\n          .map({\n            case (_ii, iiIndex) =>\n              var ii = _ii\n              import scala.util.control._\n              val find_fileset_version = new Breaks\n              find_fileset_version.breakable {\n                if (ii.getAs[String](\"version_date\") >= p_filedate) {\n                  current_fileset_version = ii.getAs[String](\"version\")\n                  outer_loop.break\n                }\n              }\n          })\n          .toArray\n      }\n      if (\n        (try current_fileset_version\n        catch {\n          case error: Throwable => null\n        }) == null\n      )\n        p_default_fileset_version\n      else if (current_fileset_version.isEmpty) p_default_fileset_version\n      else current_fileset_version\n    },\n    StringType\n  )"}